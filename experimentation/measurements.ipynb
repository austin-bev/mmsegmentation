{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch, torchvision\n",
    "import mmseg\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mmcv import Config\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmseg.apis import set_random_seed\n",
    "from mmseg.utils import get_device\n",
    "from mmseg.datasets import build_dataset, build_dataloader\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor, single_gpu_test\n",
    "from torchsummary import summary\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmseg.apis import single_gpu_test\n",
    "from mmseg.datasets.builder import build_dataloader\n",
    "from mmcv.parallel import MMDataParallel, MMDistributedDataParallel\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "config = \"configs/2023-03-20-09-19-04_Camvid11Dataset_DepthwiseSeparableFCNHead_ResNet.py\"\n",
    "checkpoint = \"work_dirs/experimentation/2023-03-20-09-19-04_Camvid11Dataset_DepthwiseSeparableFCNHead_ResNet/best_mIoU_epoch_961.pth\"\n",
    "cfg = Config.fromfile(config)\n",
    "datasets = [build_dataset(cfg.data.val)]\n",
    "\n",
    "palette = datasets[0].PALETTE\n",
    "classes = datasets[0].CLASSES\n",
    "\n",
    "model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "checkpoint = load_checkpoint(model, checkpoint)\n",
    "checkpoint['meta']['CLASSES'] = classes\n",
    "checkpoint['meta']['PALETTE'] = palette\n",
    "\n",
    "datasets = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        datasets,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=1)\n",
    "model.CLASSES = datasets.CLASSES\n",
    "model = MMDataParallel(model, device_ids=[0])\n",
    "\n",
    "single_gpu_test(model, data_loader, out_dir=\"./results/\"+cfg.filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save inference results as images.\n",
    "save_root = \"inference/camvid11/resnet32-s2-fast-sccn-decoder/\"\n",
    "data_root = \"data/CamVid11/val/\"\n",
    "for file in mmcv.scandir(data_root, suffix=\".png\"):\n",
    "    img_dir = osp.join(data_root, file)\n",
    "    result = inference_segmentor(model, img_dir)\n",
    "    arr = np.asarray(result[0])\n",
    "    img = Image.fromarray(arr.astype(np.uint8))\n",
    "    \n",
    "    img.save(save_root + str(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print inference results\n",
    "for data in data_loader:\n",
    "    with torch.no_grad():\n",
    "        result = inference_segmentor(model, datasets)\n",
    "    print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c745df823b0b8fbc96bd327094d24a497ca88aeabc85de830d0531f0a8d26eb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
