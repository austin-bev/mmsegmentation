{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation.ipynb\n",
    "\n",
    "This file creates custom mmsegmentation config files, trains models, and logs them to wandb (Weights and Biases).\n",
    "\n",
    "Thanks to Bradley for putting this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and Biases \n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch, torchvision\n",
    "import mmseg\n",
    "import mmcv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from mmcv import Config\n",
    "from mmseg.apis import inference_segmentor, init_segmentor, show_result_pyplot\n",
    "from mmseg.core.evaluation import get_palette\n",
    "from mmseg.apis import set_random_seed\n",
    "from mmseg.utils import get_device\n",
    "from mmseg.datasets import build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import train_segmentor\n",
    "\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_wandb = True\n",
    "create_config = False\n",
    "create_dir = True\n",
    "custom_backbone = True\n",
    "custom_head = True\n",
    "\n",
    "\n",
    "base_config=\"fcn_head_generic.py\"\n",
    "\n",
    "cfg = Config.fromfile('configs/' + base_config)\n",
    "data_root=\"data/cityscapes\"\n",
    "\n",
    "cfg.num_classes = 12 # Camvid: 11 + 1 void\n",
    "cfg.dataset_type = \"Cityscapes11Dataset\"\n",
    "cfg.data_root = data_root\n",
    "\n",
    "cfg.batch_size = 4\n",
    "cfg.workers_per_gpu = 1\n",
    "\n",
    "cfg.optimizer.lr=0.045\n",
    "cfg.optimizer.momentum=0.9\n",
    "\n",
    "cfg.runner.type = \"EpochBasedRunner\" \n",
    "cfg.runner.max_epochs = 500\n",
    "cfg.runner.max_iters = None\n",
    "cfg.log_config.interval = 1\n",
    "cfg.evaluation.interval = 1\n",
    "cfg.checkpoint_config.interval = 100\n",
    "\n",
    "cfg.evaluation.save_best=\"mIoU\"\n",
    "cfg.evaluation.by_epoch = True\n",
    "cfg.checkpoint_config.by_epoch = True\n",
    "cfg.lr_config.by_epoch = True\n",
    "\n",
    "# Since we use only one GPU, BN is used instead of SyncBN\n",
    "cfg.norm_cfg = dict(type='BN', requires_grad=True, momentum=0.01)\n",
    "cfg.img_norm_cfg = dict(\n",
    "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
    "cfg.model.backbone.norm_cfg = cfg.norm_cfg\n",
    "cfg.model.decode_head.norm_cfg = cfg.norm_cfg\n",
    "\n",
    "cfg.crop_size = (480, 640) # original // 1.5\n",
    "\n",
    "model_comment = \"Cityscapes. ResNet34, 2 stages\"\n",
    "\n",
    "# Backbone config\n",
    "if custom_backbone:\n",
    "    cfg.model.backbone.type='ResNet'\n",
    "    cfg.model.backbone.depth=34\n",
    "    cfg.model.backbone.pretrained='open-mmlab://resnet34'\n",
    "    cfg.model.backbone.num_stages=2\n",
    "    cfg.model.backbone.strides=(1,2)\n",
    "    cfg.model.backbone.dilations=(1,1)\n",
    "    cfg.model.backbone.out_indices=(0,1)\n",
    "    cfg.model.backbone.contract_dilation=True\n",
    "# Decode head config\n",
    "if custom_head:\n",
    "    cfg.model.decode_head.type=\"FCNHead\"\n",
    "    cfg.model.backbone.pretrained=None\n",
    "    cfg.model.decode_head.in_channels=128\n",
    "    cfg.model.decode_head.in_index=-1\n",
    "    cfg.model.decode_head.channels=64\n",
    "    cfg.model.decode_head.num_classes=cfg.num_classes\n",
    "    cfg.model.decode_head.kernel_size=3\n",
    "    cfg.model.decode_head.dropout_ratio=0.45\n",
    "\n",
    "\n",
    "cfg.train_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(type='LoadAnnotations'),\n",
    "    dict(type='Resize', img_scale=(720, 960), ratio_range=(0.5, 2.0)),\n",
    "    dict(type='RandomCrop', crop_size=cfg.crop_size, cat_max_ratio=0.75),\n",
    "    dict(type='RandomFlip', flip_ratio=0.5),\n",
    "    dict(type='PhotoMetricDistortion'),\n",
    "    dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "    dict(type='Pad', size=cfg.crop_size, pad_val=0, seg_pad_val=255),\n",
    "    dict(type='DefaultFormatBundle'),\n",
    "    dict(type='Collect', keys=['img', 'gt_semantic_seg']),\n",
    "]\n",
    "\n",
    "cfg.test_pipeline = [\n",
    "    dict(type='LoadImageFromFile'),\n",
    "    dict(\n",
    "        type='MultiScaleFlipAug',\n",
    "        img_scale=(720, 960),\n",
    "        flip=False,\n",
    "        transforms=[\n",
    "            dict(type='Resize', keep_ratio=True),\n",
    "            dict(type='RandomFlip'),\n",
    "            dict(type='Normalize', **cfg.img_norm_cfg),\n",
    "            dict(type='ImageToTensor', keys=['img']),\n",
    "            dict(type='Collect', keys=['img']),\n",
    "        ])\n",
    "]\n",
    "\n",
    "\n",
    "cfg.data.samples_per_gpu = cfg.batch_size\n",
    "cfg.data.workers_per_gpu = cfg.workers_per_gpu\n",
    "\n",
    "cfg.data.train.type = cfg.dataset_type\n",
    "cfg.data.train.data_root = cfg.data_root\n",
    "cfg.data.train.img_dir = \"leftImg8bit/train\"\n",
    "cfg.data.train.ann_dir = \"gtFine/train\"\n",
    "cfg.data.train.pipeline = cfg.train_pipeline\n",
    "\n",
    "cfg.data.val.type = cfg.dataset_type\n",
    "cfg.data.val.data_root = cfg.data_root\n",
    "cfg.data.val.img_dir = \"leftImg8bit/val\"\n",
    "cfg.data.val.ann_dir = \"gtFine/val\"\n",
    "cfg.data.val.pipeline = cfg.test_pipeline\n",
    "\n",
    "cfg.data.test.type = cfg.dataset_type\n",
    "cfg.data.test.data_root = cfg.data_root\n",
    "cfg.data.test.img_dir = \"leftImg8bit/val\"\n",
    "cfg.data.test.ann_dir = \"gtFine/val\"\n",
    "cfg.data.test.pipeline = cfg.test_pipeline\n",
    "\n",
    "\n",
    "# Using pre-trained segmentation model\n",
    "# cfg.load_from = 'work_dirs/experimentation.pth'\n",
    "\n",
    "is_pretrained = False\n",
    "\n",
    "if (\"pretrained\" in cfg.model.backbone):\n",
    "    if cfg.model.backbone[\"pretrained\"] is not None:\n",
    "        is_pretrained = True\n",
    "if (\"pretrained\" in cfg.model):\n",
    "    if cfg.model[\"pretrained\"] is not None:\n",
    "        is_pretrained = True\n",
    "\n",
    "\n",
    "# Create config name based on whether weights (backbone) are trained from scratch\n",
    "if is_pretrained:\n",
    "    config_filename = str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")) + \"_\" + \\\n",
    "        str(cfg.dataset_type) + \"_\" + \\\n",
    "        str(cfg.model.decode_head.type) + \"_\" + \\\n",
    "        str(cfg.model.backbone.type) + \".py\"\n",
    "else:\n",
    "    config_filename = str(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")) + \"_\" + \\\n",
    "        str(cfg.dataset_type) + \"_\" + \\\n",
    "        str(cfg.model.decode_head.type) + \"_\" + \\\n",
    "        str(cfg.model.backbone.type) + \"_scratch\" + \".py\"\n",
    "\n",
    "    \n",
    "if create_dir:\n",
    "    # Set up working dir to save files and logs.\n",
    "    cfg.work_dir = './work_dirs/experimentation/' + config_filename[:-3]\n",
    "    # Create work_dir\n",
    "    mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "\n",
    "\n",
    "# Set seed for result reproduction\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "cfg.device = get_device()\n",
    "\n",
    "\n",
    "wandb_cfg_dict = {\n",
    "    \"learning_rate\": cfg.optimizer.lr,\n",
    "    \"momentum\": cfg.optimizer.momentum,\n",
    "    \"batch_size\": cfg.batch_size,\n",
    "    \"backbone\": cfg.model.backbone.type,\n",
    "    \"decodehead\": cfg.model.decode_head.type,\n",
    "    \"dataset\": cfg.dataset_type,\n",
    "    \"epochs\": cfg.runner.max_epochs,\n",
    "    \"is_pretrained\": is_pretrained,\n",
    "    \"comment\":model_comment\n",
    "}\n",
    "\n",
    "cfg.log_config.hooks[0].by_epoch=True\n",
    "\n",
    "# Log to WandB\n",
    "if use_wandb:\n",
    "    cfg.log_config.hooks.append(\n",
    "        dict(type='MMSegWandbHook', by_epoch=True, # The Wandb logger is also supported, It requires `wandb` to be installed.\n",
    "                init_kwargs={'entity': \"austin-bevac\", # The entity used to log on Wandb\n",
    "                            'project': \"2023-honours-austin\", # Project name in WandB\n",
    "                            'config': wandb_cfg_dict,\n",
    "                            'name': config_filename[:-3]})\n",
    "    )\n",
    "\n",
    "# Create config file\n",
    "if create_config:\n",
    "    cfg.dump(\"configs/\" + str(config_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile(\"./configs/2023-04-07-23-37-11_Camvid11Dataset_DepthwiseSeparableFCNHead_ResNet.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_segmentor(cfg.model)\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(total_params)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_segmentor(model, datasets, cfg, distributed=False, validate=True, meta=dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual config file creation \n",
    "cfg.dump(\"configs/\" + str(config_filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c745df823b0b8fbc96bd327094d24a497ca88aeabc85de830d0531f0a8d26eb1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
